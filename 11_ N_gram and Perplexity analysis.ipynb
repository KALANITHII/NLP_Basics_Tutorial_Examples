{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Exploring Corpus Statistics and N-gram Analysis in Python\"\n",
    "\n",
    "This notebook features a customizable n-gram analysis program applied to two distinct small corpora, facilitating a comparative study of their statistics. Users can choose corpora such as email text or newsgroups and leverage the program to examine differences in the most common unigrams and intriguing disparities in bigrams between the two datasets. Additionally, the program offers options to generate random sentences and compute perplexity for a test set, enhancing its versatility for linguistic exploration and text analysis. This comprehensive tool provides insights into corpus variances and n-gram patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    words = text.split()\n",
    "    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(ngrams):\n",
    "    model = defaultdict(int)\n",
    "    for ngram in ngrams:\n",
    "        model[ngram] += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, n, max_length):\n",
    "    sentence = []\n",
    "    current_ngram = random.choice(list(model.keys()))\n",
    "    \n",
    "    for i in range(min(max_length, len(current_ngram))):\n",
    "        sentence.append(current_ngram[i])\n",
    "\n",
    "    while len(sentence) < max_length:\n",
    "        next_word = random.choices(list(model.keys()))[0][-1]\n",
    "        sentence.append(next_word)\n",
    "        current_ngram = current_ngram[1:] + (next_word,)\n",
    "    return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is a measure of how well a language model predicts a given sequence of words. It quantifies the uncertainty or average branching factor of the model, with lower perplexity indicating better predictive performance. It is commonly used to evaluate the effectiveness of language models in natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, test_ngrams, n):\n",
    "    log_prob = 0\n",
    "    for test_ngram in test_ngrams:\n",
    "        context = test_ngram[:-1]\n",
    "        next_word = test_ngram[-1]\n",
    "        context_ngrams = [ngram for ngram in model if ngram[:-1] == context]\n",
    "        next_word_ngrams = [ngram for ngram in context_ngrams if ngram[-1] == next_word]\n",
    "        if next_word_ngrams:\n",
    "            probability = (sum(model[ngram] for ngram in next_word_ngrams) + 1) / (sum(model[ngram] for ngram in context_ngrams) + len(model))\n",
    "        else:\n",
    "            probability = 1 / len(model)\n",
    "        log_prob += log2(probability)\n",
    "    perplexity = 2 ** (-log_prob/len(test_ngrams))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    email_text = open(r\"data\\email_text.txt\", \"r\").read()\n",
    "    newsgroups = open(r\"data\\newsgroups.txt\", \"r\").read()\n",
    "\n",
    "    email_text = preprocess_text(email_text)\n",
    "    email_ngrams = generate_ngrams(email_text, 2)\n",
    "    newsgroups_text = preprocess_text(newsgroups)\n",
    "    newsgroups_ngrams = generate_ngrams(newsgroups_text,2)\n",
    "\n",
    "    email_model = build_ngram_model(email_ngrams)\n",
    "    newsgroups_model = build_ngram_model(newsgroups_ngrams)\n",
    "\n",
    "    print(\"Most common unigrams in email text:\")\n",
    "    print(sorted(email_model.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "    print()\n",
    "    print(\"Most common unigrams in newsgroups:\")\n",
    "    print(sorted(newsgroups_model.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "    print()\n",
    "\n",
    "    print(\"Random sentence generated using email model:\")\n",
    "    print(generate_sentence(email_model, 2, 10))\n",
    "    print()\n",
    "    \n",
    "    perplexity = calculate_perplexity(email_model, newsgroups_ngrams, 2)\n",
    "    print(\"Perplexity of newsgroups corpus given email model:\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common unigrams in email text:\n",
      "[(('followup', 'meeting'), 4), (('you', 'have'), 4), (('from', 'john'), 2), (('john', 'doe'), 2), (('doe', 'johndoeemailcom'), 2)]\n",
      "\n",
      "Most common unigrams in newsgroups:\n",
      "[(('the', 'latest'), 3), (('on', 'the'), 3), (('the', 'economy'), 3), (('for', 'the'), 2), (('the', 'government'), 2)]\n",
      "\n",
      "Random sentence generated using email model:\n",
      "feel free be out the please quick from sure just\n",
      "\n",
      "Perplexity of newsgroups corpus given email model: 58.58659522692783\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlplab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80223e0b96b21b6ab94bb3c1b14fbef17ccb8d987f3443ee0ec439dd0b212109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
